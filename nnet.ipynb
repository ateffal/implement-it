{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implement a neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from scipy.special import expit, logit, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a simple neural network with one hidden layer with n neurones and an output layer\n",
    "class Simple_nnet:\n",
    "\n",
    "    def __init__(self, input_shape , hidden_layer_shape = 16, output_shape = 2) :\n",
    "        self.input_shape = input_shape\n",
    "        self.hidden_layer_shape = hidden_layer_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        # init wheights and bias for hidden layer with random numbers \n",
    "        self.h_weights = rd.rand(hidden_layer_shape, input_shape)\n",
    "        self.h_bias = rd.rand(hidden_layer_shape, 1)\n",
    "\n",
    "        # init wheights and bias for output layer with random numbers \n",
    "        self.o_weights = rd.rand(output_shape, hidden_layer_shape)\n",
    "        self.o_bias = rd.rand(output_shape, 1)\n",
    "\n",
    "    def process_input(self, input):\n",
    "        # reshape input\n",
    "        input = np.reshape(input, (input.shape[0], 1))\n",
    "        # calculate hidden layer neurones. @ operator do matrix multiplication\n",
    "        a1 = (self.h_weights @ input )+ self.h_bias\n",
    "        a1 = expit(a1) # apply sigmoid function\n",
    "\n",
    "        # calculate output layer. @ operator do matrix multiplication\n",
    "        a2 = (self.o_weights @ a1 )+ self.o_bias\n",
    "        a2 = softmax(a2) # apply softmax function\n",
    "        \n",
    "        return a2\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.input_shape) + \" --> \" + str(self.hidden_layer_shape) + \" --> \" + str(self.output_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet1 = Simple_nnet(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = np.array([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53883862],\n",
       "       [0.46116138]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet1.process_input(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax([10, 20])[0] + softmax([10, 20])[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function (the output layer has $ n_o $ neurones): \n",
    "\n",
    "$$\n",
    "  C =  \\frac{1}{2} \\sum_{i=1}^{n_o} (\\hat{y}_{i} - y_i)^2\n",
    "$$\n",
    "\n",
    "So : \n",
    "\n",
    "$$\n",
    "\\frac{\\partial{C}}{\\hat{y}_{i}} = \\hat{y}_{i} - y_i\n",
    "\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation for the last layer (output) : </br>\n",
    "$$ \n",
    "a_i^{o} = \\sigma (z_i^{o}) = \\hat{y}_{i} \n",
    "$$\n",
    "\n",
    "where :\n",
    "$$\n",
    "z_i^{o} = \\sum_{k=1}^{n_H} W_{i, k}^{o}.a_{k}^{H} + b_{i}^{o}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's calculate the gradients of cost with regards to bias $ b_i^{o} $ . <br>\n",
    "For this, we need to understand how each term depends on the other so that we can use the chain rule. <br>\n",
    "This notation : Y &rarr; X, mean that Y depends on X, and if it's the case, generally we calculate the derivative of Y with regards to X : $  \\frac{\\partial{Y}}{\\partial{X}} $. <br>\n",
    "In our case, we have these dependencies (see formulas above): C &rarr; $ a_{i}^{o} $ &rarr; $ z_{i}^{o} $ &rarr; $ b_{i}^{o} $. <br>\n",
    "So we can use the chain rule to calculate gradient of cost with regards to $ b_i $ : \n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\partial{C}}{\\partial{b_{i}^{o}}} = \\frac{\\partial{C}}{\\partial{a_{i}^{o}}} \\times \\frac{\\partial{a_{i}^{o}}}{\\partial{z_{i}^{o}}} \\times \\frac{\\partial{z_{i}^{o}}}{\\partial{b_{i}^{o}}}\n",
    "\n",
    "$$\n",
    "\n",
    "Let's calculate each term in the right separately : \n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\partial{C}}{\\partial{a_{i}^{o}}} = (a_{i}^{o} - y_{i})\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\partial{a_{i}^{o}}}{\\partial{z_{i}^{o}}} = \\sigma^{'}(z_{i}^{o}) = \\sigma(z_{i}^{o}) \\times (1 - \\sigma(z_{i}^{o})) = a_{i}^{o} \\times (1 - a_{i}^{o})\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    " \\frac{\\partial{z_{i}^{o}}}{\\partial{b_{i}^{o}}} = 1\n",
    "$$\n",
    "So : \n",
    "\n",
    "$$\n",
    "    \\frac{\\partial{C}}{\\partial{b_{i}^{o}}} = (a_{i}^{o} - y_{i}) \\times a_{i}^{o} \\times (1 - a_{i}^{o})\n",
    "$$\n",
    "NB : Remenber that : $ a_{i}^{o} = \\hat{y}_{i} $ \n",
    "The following function implements just this : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient_output_bias(y_hat, y):\n",
    "\n",
    "    \"\"\"\n",
    "        Calculate the gradient of cost function with regards to the bias of output layer. \n",
    "        The cost function is : 1/2 * some(y_hat_i - y_i) , i = 1,...,n_o , n_o is the the length of output\n",
    "        y_hat : output vector\n",
    "        y : ground truth vector of the same lenth as y_hat\n",
    "    \"\"\"\n",
    "\n",
    "    return (y_hat-y)*y_hat*(1-y_hat)\n",
    "\n",
    "# test function\n",
    "y_hat = np.array([1, 2])\n",
    "y = np.array([0.5, 1.5])\n",
    "gradient_output_bias(y_hat, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to the gradients with regards to the weights of the output layer : \n",
    "$$\n",
    "\n",
    "\\frac{\\partial{C}}{\\partial{W_{i, k}^{o}}}\n",
    "\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will again the rule chain : \n",
    "$$\n",
    "\n",
    "\\frac{\\partial{C}}{\\partial{W_{i, k}^{o}}} = \\frac{\\partial{C}}{\\partial{a_{i}^{o}}} \\times \\frac{\\partial{a_{i}^{o}}}{\\partial{z_{i}^{o}}} \\times \\frac{\\partial{z_{i}^{o}}}{\\partial{W_{i, k}^{o}}}\n",
    "\n",
    "$$\n",
    "\n",
    "The two first terms were already calculated (see above) : \n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\partial{C}}{\\partial{a_{i}^{o}}} = (a_{i}^{o} - y_{i})\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial{a_{i}^{o}}}{\\partial{z_{i}^{o}}} =  a_{i}^{o} \\times (1 - a_{i}^{o})\n",
    "$$\n",
    "\n",
    "For the third term, we know that : $ z_i^{o} = \\sum_{k=1}^{n_H} W_{i, k}^{o}.a_{k}^{H} + b_{i}^{o} $, so : \n",
    "\n",
    "$$\n",
    "\n",
    "    \\frac{\\partial{z_{i}^{o}}}{\\partial{W_{i, k}^{o}}} = a_{k}^{H}\n",
    "$$\n",
    "\n",
    "Therfore : \n",
    "$$\n",
    "    \\frac{\\partial{C}}{\\partial{W_{i, k}^{o}}} = (a_{i}^{o} - y_{i}) \\times a_{i}^{o} \\times (1 - a_{i}^{o}) \\times a_{k}^{H}\n",
    "$$\n",
    "\n",
    "<b> NB : Remenber that : $ a_{i}^{o} = \\hat{y}_{i} $ </b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement this calculations in a function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_output_weights(a_o, a_h, y):\n",
    "\n",
    "    \"\"\"\n",
    "        Calculate the gradient of cost function with regards to the weights of output layer. \n",
    "        a_o : vector of dimension no, activation of output ( = y_hat)\n",
    "        a_h : vector of dimension nh, activation of hidden layer\n",
    "        y : ground truth vector of the same lenth as y_hat\n",
    "    \"\"\"\n",
    "\n",
    "    # first we need to get dimensions of a_o and a_h\n",
    "    no = len(a_o) # equals dim of y \n",
    "    nh = len(a_h)\n",
    "\n",
    "    # intermidate calculs (multiplication of the 3 first terms in eq. above)\n",
    "    temp = (a_o - y) * a_o * (1 - a_o) # here we get a vector of length no\n",
    "\n",
    "    # reshape vectors to make matrix multiplication\n",
    "    temp = temp.reshape((no, 1))\n",
    "    a_h = a_h.reshape((1, nh))\n",
    "\n",
    "    return temp @ a_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. ],\n",
       "       [-3. , -4. , -3.2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xaf{\\x80\\x881\\xb1I\\xf6%d\\xbdU5\\xc2^\\x87 \\x9b F\\xa8\\xcf&5S_h\\xfb\\x8d\\x01\\xd4\\x11']\n",
      "Bad pipe message: %s [b'\\xeb\\x85\\xda=\\xd4\\xb7sF\\xf9,\\x18~R\\x11\\xb6Qh4\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#']\n",
      "Bad pipe message: %s [b'\\xcc\\x82\\xfb\\xd6\\xc8\\t\\xec\\x85\\xcb\\x15\\xf1a\\x97\\x82\\x1a{\\xd2\\xa2\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f']\n",
      "Bad pipe message: %s [b'W\\xc1\\r\\x86H\\x8bx\\xe1\\xd7\\x90MJ\\xbf\\xd8|-\\xe1\\x9d\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t12']\n",
      "Bad pipe message: %s [b'0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01']\n",
      "Bad pipe message: %s [b'UQ\\xa1\\xf1\\x91\\xeao\\xa3\\x07\\xa0\\x08\\x9c#\\x9eR\\xc3\\x9e\\x9c\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00']\n",
      "Bad pipe message: %s [b'\\x12\\xc0\\x08']\n",
      "Bad pipe message: %s [b\"\\xc00M\\x8a\\x1c\\x16F\\x80i$%\\x92xM\\x0bZ7\\\\\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\", b'\\x11\\xc0\\x07\\xc0\\x0c\\xc0']\n",
      "Bad pipe message: %s [b'\\x05']\n",
      "Bad pipe message: %s [b'\\xd4\\x0b\\xac\\xf8\\x9eS\\xbd\\x02\\xb9\\x0f4_\\x84\\x9b#.+\\x81\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0']\n",
      "Bad pipe message: %s [b'\\x9d\\x00=\\x00']\n",
      "Bad pipe message: %s [b\"\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00\"]\n",
      "Bad pipe message: %s [b'\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17']\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "a_o_1 = np.array([1, 2])\n",
    "y_1 = np.array([0.5, 1.9])\n",
    "a_h_1 = np.array([15, 20, 16])\n",
    "\n",
    "gradient_output_weights(a_o_1, a_h_1, y_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to the gradients with regards to the hidden layer :\n",
    "$$\n",
    "\n",
    "\\frac{\\partial{C}}{\\partial{b_{i}^{H}}} = \\frac{\\partial{C}}{\\partial{z_{1}^{o}}} \\times \\frac{\\partial{z_{1}^{o}}}{\\partial{b_{1}^{H}}} + \\frac{\\partial{C}}{\\partial{z_{2}^{o}}} \\times \\frac{\\partial{z_{2}^{o}}}{\\partial{b_{1}^{H}}}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
